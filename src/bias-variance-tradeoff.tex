\section{Bias-Variance Tradeoff}
\emph{A choice between more complex, low-bias hypotheses that fit the training data well, and simpler,
low-variance hypotheses that may generalize better.
}

Machine learning models can only approximate the true function for the relationship
between features.

\textbf{Bias} is the tendency of a predictive hypothesis to deviate from the expected value
when averaged over different training sets.

When a model fails to capture the true relationship between features,
it has high bias, and tends to \textbf{underfit}.

\textbf{Variance} is the amount of change in the hypothesis due to 
differences in datasets.

When a model fits a training set really well but performs poorly on a testing set,
it is said to \textbf{overfit}.