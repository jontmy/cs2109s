# Week 2 — Uninformed Search #

## Table of Contents ##

- [Week 2 — Uninformed Search](#week-2--uninformed-search)
  - [Table of Contents](#table-of-contents)
  - [Problem-Solving Agents](#problem-solving-agents)
    - [Single-state Problem Formulation](#single-state-problem-formulation)
    - [Abstracting State Spaces](#abstracting-state-spaces)
  - [Tree Search Algorithms](#tree-search-algorithms)
    - [Implementation](#implementation)
    - [Measuring Performance](#measuring-performance)
      - [An Aside: Time and Space Complexity](#an-aside-time-and-space-complexity)
  - [Uninformed Search Strategies](#uninformed-search-strategies)
    - [Breadth-first Search](#breadth-first-search)
    - [Uniform-cost Search](#uniform-cost-search)
    - [Depth-first Search](#depth-first-search)
    - [Depth-limited Search](#depth-limited-search)
    - [Iterative Deepening Search](#iterative-deepening-search)
    - [Bidirectional Search](#bidirectional-search)
      - [An Aside: Dealing with Repeated States](#an-aside-dealing-with-repeated-states)
    - [Summary](#summary)

## Problem-Solving Agents ##

```python
class SimpleProblemSolvingAgentProgram:

    def __init__(self, initial_state=None):
        """State is an abstract representation of the state
        of the world, and seq is the list of actions required
        to get to a particular state from the initial state(root)."""
        self.state = initial_state
        self.seq = []

    def __call__(self, percept):
        """Formulate a goal and problem, then
        search for a sequence of actions to solve it."""
        self.state = self.update_state(self.state, percept)
        if not self.seq:
            goal = self.formulate_goal(self.state)
            problem = self.formulate_problem(self.state, goal)
            self.seq = self.search(problem)
            if not self.seq:
                return None
        return self.seq.pop(0)

    def update_state(self, state, percept):
        pass  # ...

    def formulate_goal(self, state):
        pass  # ...

    def formulate_problem(self, state, goal):
        pass  # ...

    def search(self, problem):
        pass  # ...
```

Agents may need to **consider a sequence of actions** that form a path to a goal state when the correct action is not immediately obvious. In order to do so, agents usually follow a four-phase problem-solving process:

1. **Goal formulation**: Goals limit objectives and hence the actions that need to be considered.
2. **Problem formulation**: Describe the states and actions necessary to reach the goal.
3. **Search**: Derive a **solution**, which is a sequence of actions from the initial state that reaches a goal state. There may be multiple possible solutions, or even no solution.
4. **Execute**: Perform the actions in the solution.

There are many different search problem types depending on the environment:

- Deterministic, fully observable: **Single-state problem**
  - The agent knows exactly where it will be.
- Non-observable: **Sensorless/conformant problem**
  - The agent may have no idea where it is.
- Non-deterministic, and/or partially observable: **Contingency problem**
  - Percepts provide new information about the current state.
  - Often interleaves search and execution.
- Unknown environment states: **Exploration problem**

### Single-state Problem Formulation ###

The environment can exist in many possible states, collectively referred to as the **state space**.

A search problem is formally defined by four items:

1. The **initial state** the agent starts in.
2. The **actions** available to the agent. Given a state `x`, the successor function `S(x)` returns a set of **action-state pairs**.
3. The **goal test**, which can be defined **explicitly** as a condition, or **implicitly** as a function which takes a state. For example, `checkmate(x)` is defined implicitly.
4. The **path cost function** `c(x, a, y)` which gives the additive cost of performing the action `a` at state `x` to reach state `y`.

### Abstracting State Spaces ###

The real world is absurdly complex, with a state space that is too huge.

> Section is incomplete; to be expanded.

## Tree Search Algorithms ##

A **search algorithm** takes a search problem as input and returns a solution or an indication of failure. **In essence, a tree search simulates the exploration of the state space by generating sucessors of already-explored states**, starting from the initial state.

### Implementation ###

A **state** is a representation of a physical configuration of the environment.

A **node** in the search tree corresponds to a state in the state space. The **edges** of the search tree correspond to actions. **As a data structure, nodes include state, parent nodes, actions, path cost, and depth.**

The `expand` function creates new nodes using the `successor` function to create the corresponding states.

> Section is incomplete; to be expanded in more detail.

### Measuring Performance ###

The order of node expansion defines the **search strategy** used by a search algorithm.
However, we first need criteria to evaluate them, and we can do so along four dimensions:

1. **Completeness**: Is it guaranteed to find a solution if one exists? A complete algorithm must be able to explore every state reachable from the initial state.
2. **Time complexity**: How many nodes does it generate?
3. **Space complexity**: How much memory does it need to store the nodes at maximum?
4. **Cost optimality**: Does it always find a least-cost solution among all solutions?

#### An Aside: Time and Space Complexity ####

In a state-space graph, theoretical algorithm analysis suggests complexity as measured based on `|V| + |E|`, where `|V|` is the number of vertices (state nodes) and `|E|` is the number of edges (state-action pairs).

> However, in many AI problems, the graph is represented only implicitly by the initial state and actions.

Therefore, complexity here is measured in terms of:

- `b`, the maximum **branching factor** of the search tree,
- `d`, the **depth of the least-cost solution**, and
- `m`, the **maximum depth of the state-space** (number of actions in any path)

## Uninformed Search Strategies ##

**Uninformed** search strategies use only the information given in the problem definition. They have no knowledge on how close a state is to any goal.

### Breadth-first Search ###

```python
def breadth_first_graph_search(problem):
    node = Node(problem.initial)
    if problem.goal_test(node.state):
        return node

    frontier = deque([node])
    explored = set()

    while frontier:
        node = frontier.popleft()
        explored.add(node.state)
        for child in node.expand(problem):
            if child.state not in explored and child not in frontier:
                if problem.goal_test(child.state):
                    return child
                frontier.append(child)
    return None
```

In **breath-first search**, the root node is expanded first, followed by all its successors. An implementation (by AIMA) using a **FIFO queue** is given above.

A slight optimization in the form of **early goal tests** exists whereby goal tests are performed for nodes when they are generated rather than popped (**late goal test**).

1. **Completeness**: Yes, if `b` is finite.
2. **Time complexity**: <code>O(b<sup>d + 1</sup>) = 1 + b + b<sup>2</sup> + b<sup>3</sup> + ... + b<sup>d</sup></code>
3. **Space complexity**: <code>O(b<sup>d + 1</sup>)</code> since all nodes remain in memory.
4. **Cost optimality**: Yes, if all actions have the same cost.

> The space complexity of breadth-first search is a bigger problem than its time complexity.
> In general, exponential-complexity search problems cannot be solved by uninformed search for any but the smallest instances.

### Uniform-cost Search ###

```python
def best_first_graph_search(problem, f):
    f = memoize(f, 'f')
    node = Node(problem.initial)
    frontier = PriorityQueue('min', f)
    frontier.append(node)
    explored = set()

    while frontier:
        node = frontier.pop()
        if problem.goal_test(node.state):
            return node
        explored.add(node.state)

        for child in node.expand(problem):
            if child.state not in explored and child not in frontier:
                frontier.append(child)
            elif child in frontier:
                if f(child) < frontier[child]:
                    del frontier[child]
                    frontier.append(child)
    return None


def uniform_cost_search(problem, display=False):
    return best_first_graph_search(problem, lambda node: node.path_cost, display)
```

Also known as **Dijkstra's algorithm**, **uniform-cost search** always expands the least-cost unexpanded node. It is equivalent to breadth-first search if all action costs are equal. An implementation (by AIMA) using a **priority queue ordered by path cost** is given above.

Let `C*` be the cost of the optimal solution, and `ε` be the lower bound on each action cost where `ε > 0`.

1. **Completeness**: Yes, if all action costs `>= ε > 0`.
2. **Time complexity**: <code>O(b<sup>ceil(C* / ε)</sup>)</code>
3. **Space complexity**:<code>O(b<sup>ceil(C* / ε)</sup>)</code>
4. **Cost optimality**: Yes, since nodes are expanded in order of increasing cost.

> <code>b<sup>ceil(C* / ε)</sup></code> can be worse than <code>b<sup>d</sup></code> since uniform-cost search can explore large trees of actions with low costs before exploring paths with a high-cost but with useful action.

### Depth-first Search ###

```python
def depth_first_graph_search(problem):
    """
    Search the deepest nodes in the search tree first.
    Search through the successors of a problem to find a goal.
    The argument frontier should be an empty queue.
    Does not get trapped by loops.
    If two paths reach a state, only use the first one.
    """
    frontier = [(Node(problem.initial))]  # Stack

    explored = set()
    while frontier:
        node = frontier.pop()
        if problem.goal_test(node.state):
            return node
        explored.add(node.state)
        frontier.extend(child for child in node.expand(problem)
                        if child.state not in explored and child not in frontier)
```

In **depth-first search**, the deepest node is always expanded first.

1. **Completeness**: Depends. Incomplete if it fails in loops (for some implementations) or infinite-depth spaces. Complete in finite spaces.
2. **Time complexity**: `O(bm)`
3. **Space complexity**: `O(bm)` without backtracking, `O(m)` with backtracking.
4. **Cost optimality**: No, since it always returns the first solution it finds.

> The time complexity of `O(bm)` can be terrible if `m` is much larger than `d`. However, DFS can be faster than BFS if the goals are dense.

### Depth-limited Search ###

```python
def depth_limited_search(problem, limit):
    def recursive_dls(node, problem, limit):
        if problem.goal_test(node.state):
            return node
        elif limit == 0:
            return 'cutoff'
        else:
            cutoff_occurred = False
            for child in node.expand(problem):
                result = recursive_dls(child, problem, limit - 1)
                if result == 'cutoff':
                    cutoff_occurred = True
                elif result is not None:
                    return result
            return 'cutoff' if cutoff_occurred else None

    return recursive_dls(Node(problem.initial), problem, limit)
```

Essentially, **depth-limited search** is depth-first search with a depth limit `l`, such that all nodes at depth `l` are treated as if they had no successors. This prevents DFS from wandering down an infinite path.

1. **Completeness**: No, if a poor choice of `l` is made it will fail to arrive at a solution.
2. **Time complexity**: `O(bl)`
3. **Space complexity**: `O(bl)`
4. **Cost optimality**: No, since it always returns the first solution it may find.

### Iterative Deepening Search ###

```python
def iterative_deepening_search(problem):
    for depth in range(sys.maxsize):
        result = depth_limited_search(problem, depth)
        if result != 'cutoff':
            return result
```

Rather than having to choose a single value for `l` like in DLS, **iterative deepening search** tries every possible value for `l` incrementally from zero.

There is an overhead cost to doing so, but most of the nodes are in the bottom level, so repetition of the top nodes is not entirely significant.

For example, for `b = 10` and `d = 5`,

- DLS explores `1 + 10 + 100 + 1000 + 10000 = 11111` nodes.
- IDS explores `6 + 50 + 400 + 3,000 + 20,000 + 100,000 = 123,456` nodes.
- The overhead is a mere `11%`.

1. **Completeness**: Yes.
2. **Time complexity**: <code>O(b<sup>d</sup>) = (d + 1)b<sup>0</sup> + db<sup>1</sup> + (d - 1)b<sup>2</sup> + ... + b<sup>d</sup></code>
3. **Space complexity**: `O(bd)`
4. **Cost optimality**: Yes, if the action costs are equal.

### Bidirectional Search ###

This alternative approach searches **simultaneously** from the initial state and backwards from the goal states, checking if a node appears in the other search tree. Intuitively, <code>2 * O(b<sup>d/2</sup>)</code> is less than <code>O(b<sup>d</sup>)</code>.

Different search strategies can be employed for either half. However, `pred(succ(n)` and `succ(pred(n))` must be equal, where `pred` and `succ` are the predecessor and successor functions respectively.

#### An Aside: Dealing with Repeated States ####

> **Failure to prevent repeated states can turn linear problems to exponential ones.**

Memoization should be utilized to handle repeated states.

### Summary ###

> Section to be completed.